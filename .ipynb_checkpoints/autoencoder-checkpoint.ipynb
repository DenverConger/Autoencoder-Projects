{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from loguru import logger\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=gpus,cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_dir = \"/home/congds/class_proj/autoencoder/pics/bryan1\"\n",
    "training_dir_uch = \"/home/congds/class_proj/autoencoder/pics/uchtdorf1\"\n",
    "image_size = (256, 256)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=.2,\n",
    "        rotation_range=50,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2\n",
    "        # preprocessing_function=add_noise\n",
    "        )\n",
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=.2,\n",
    "        rotation_range=50,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2\n",
    "        # preprocessing_function=add_noise\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3758 images belonging to 1 classes.\n",
      "Found 939 images belonging to 1 classes.\n",
      "Found 1459 images belonging to 1 classes.\n",
      "Found 364 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size = image_size,\n",
    "        subset=\"training\",\n",
    "        batch_size=128,\n",
    "        class_mode='input',\n",
    "        color_mode=\"rgb\",\n",
    "        seed=42,shuffle=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=128,\n",
    "        class_mode='input',\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"validation\",\n",
    "        seed=42)\n",
    "\n",
    "\n",
    "\n",
    "train_generator_uch = train_datagen.flow_from_directory(\n",
    "        training_dir_uch,\n",
    "        target_size = image_size,\n",
    "        subset=\"training\",\n",
    "        batch_size=128,\n",
    "        class_mode='input',\n",
    "        color_mode=\"rgb\",\n",
    "        seed=42,shuffle=True)\n",
    "validation_generator_uch = validation_datagen.flow_from_directory(\n",
    "        training_dir_uch,\n",
    "        target_size=image_size,\n",
    "        batch_size=128,\n",
    "        class_mode='input',\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"validation\",\n",
    "        seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#         test_dir,\n",
    "#         classes=['test'],\n",
    "#         target_size=image_size,\n",
    "#         class_mode='sparse',\n",
    "#         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ourdata=tf.keras.preprocessing.image_dataset_from_directory(train,shuffle=True,\n",
    "#                                                      batch_size=64,image_size=(256, 256),seed=123)\n",
    "# uch=tf.keras.preprocessing.image_dataset_from_directory(train_uch,shuffle=True,\n",
    "#                                                      batch_size=64,image_size=(256, 256),seed=123)\n",
    "# def normalizer(generator):\n",
    "#   normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "#   def change_inputs(images, labels):\n",
    "#     x = tf.image.resize(normalization_layer(images),[256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "#     return x, x\n",
    "\n",
    "#   return generator.map(change_inputs)\n",
    "# normalized = normalizer(ourdata)\n",
    "# normalized_uchtdorf = normalizer(uch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /projects/fpga_packet/mambaforge/envs/5g/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def loss_func(y_true, y_predict, encoder_mu, encoder_log_variance):\n",
    "    '''    \n",
    "    Loss function: Kulback-Leibler Divergence + Reconstruction loss\n",
    "    Reconstruction loss is mean squared error\n",
    "    '''\n",
    "    reconstruction_loss_factor = 400\n",
    "    reconstruction_loss = K.mean(K.square(y_true - y_predict), axis=[1, 2, 3])\n",
    "    reconstruction_loss = reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=-1)\n",
    "\n",
    "    return reconstruction_loss + kl_loss\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (encoder_mu, encoder_log_variance) to sample encoder, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_mu, encoder_log_variance = inputs\n",
    "        batch = tf.shape(encoder_mu)[0]\n",
    "        dim = tf.shape(encoder_mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return encoder_mu + tf.exp(0.5 * encoder_log_variance) * epsilon\n",
    "\n",
    "\n",
    "\n",
    "latent_space_dim=256\n",
    "input_shape=(256,256,3)\n",
    "\n",
    "'''encoder'''\n",
    "encoder_input = tf.keras.layers.Input(shape=input_shape)\n",
    "net = tf.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1)(encoder_input)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=1)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=4)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", strides=1)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "shape_before_flatten = K.int_shape(net)[1:]\n",
    "net = tf.keras.layers.Flatten()(net)\n",
    "encoder_mu = tf.keras.layers.Dense(units=latent_space_dim)(net)\n",
    "encoder_log_variance = tf.keras.layers.Dense(units=latent_space_dim)(net)\n",
    "\n",
    "# custom layer - will not run on DPU\n",
    "encoder_z = Sampling()([encoder_mu, encoder_log_variance])\n",
    "\n",
    "# encoder_mu,encoder_log_variance outputs go to loss function\n",
    "# encoder_z is encoded latent space\n",
    "encoder=Model(inputs=encoder_input, outputs=[encoder_mu,encoder_log_variance,encoder_z])\n",
    "\n",
    "\n",
    "''' decoder '''\n",
    "decoder_input = tf.keras.layers.Input(shape=latent_space_dim)\n",
    "net = tf.keras.layers.Dense(units=np.prod(shape_before_flatten))(decoder_input)\n",
    "net = tf.keras.layers.Reshape(target_shape=shape_before_flatten)(net)\n",
    "net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=4)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "decoder_output = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), padding=\"same\", activation=\"sigmoid\",strides=1)(net)\n",
    "\n",
    "\n",
    "# standard sigmoid\n",
    "#decoder_output = Activation('sigmoid')(net)\n",
    "\n",
    "decoder = Model(inputs=decoder_input, outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 1)  28          ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 1)  4          ['conv2d[1][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 256, 256, 1)  0           ['batch_normalization[1][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 32  320         ['leaky_re_lu[1][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 32  128        ['conv2d_1[1][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 256, 256, 32  0           ['batch_normalization_1[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 64  18496       ['leaky_re_lu_1[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['conv2d_2[1][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 128, 128, 64  0           ['batch_normalization_2[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 64)   36928       ['leaky_re_lu_2[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_3[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 32, 32, 64)   0           ['batch_normalization_3[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   9232        ['leaky_re_lu_3[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 32, 32, 16)   0           ['batch_normalization_4[1][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 16384)        0           ['leaky_re_lu_4[1][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          4194560     ['flatten[1][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          4194560     ['flatten[1][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 256)          0           ['dense[1][0]',                  \n",
      "                                                                  'dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16384)        4210688     ['sampling[1][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 32, 32, 16)   0           ['dense_2[1][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 64)  9280        ['reshape[1][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_transpose[1][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 32, 32, 64)   0           ['batch_normalization_5[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 64  36928      ['leaky_re_lu_5[1][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128, 128, 64  256        ['conv2d_transpose_1[1][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 128, 128, 64  0           ['batch_normalization_6[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 64  36928      ['leaky_re_lu_6[1][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 64  256        ['conv2d_transpose_2[1][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 256, 256, 64  0           ['batch_normalization_7[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 3)  1731       ['leaky_re_lu_7[1][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,751,155\n",
      "Trainable params: 12,750,417\n",
      "Non-trainable params: 738\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_dim = 256\n",
    "image_chan = 3\n",
    "input_layer = tf.keras.layers.Input(shape=(image_dim,image_dim,image_chan))\n",
    "encoder_mu, encoder_log_variance, encoder_z = encoder.call(input_layer)\n",
    "\n",
    "dec_out = decoder.call(encoder_z)\n",
    "model = Model(inputs=input_layer, outputs=dec_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=lambda y_true,y_predict: loss_func(y_true,y_predict,encoder_mu,encoder_log_variance),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 17:56:23.345340: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 17:56:25.360785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38236 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-11-17 17:56:25.362903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38236 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2022-11-17 17:56:25.365069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38236 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2022-11-17 17:56:25.366880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38236 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "2022-11-17 17:56:25.401585: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 17:56:28.301020: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-11-17 17:56:29.423267: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - batch: 14.5000 - size: 125.2667 - loss: 352.8355 - mse: 0.0582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/fpga_packet/mambaforge/envs/5g/lib/python3.9/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 61s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 352.7711 - mse: 0.0582 - val_loss: 47.2967 - val_mse: 0.0505\n",
      "Epoch 2/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 81.2567 - mse: 0.0496 - val_loss: 45.0095 - val_mse: 0.0507\n",
      "Epoch 3/25\n",
      "30/30 [==============================] - 51s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 32.5035 - mse: 0.0482 - val_loss: 42.1526 - val_mse: 0.0504\n",
      "Epoch 4/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 24.8561 - mse: 0.0435 - val_loss: 37.2525 - val_mse: 0.0496\n",
      "Epoch 5/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 22.7950 - mse: 0.0417 - val_loss: 36.2253 - val_mse: 0.0505\n",
      "Epoch 6/25\n",
      "30/30 [==============================] - 51s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 21.7935 - mse: 0.0408 - val_loss: 33.3534 - val_mse: 0.0506\n",
      "Epoch 7/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 21.0868 - mse: 0.0401 - val_loss: 31.4615 - val_mse: 0.0505\n",
      "Epoch 8/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 20.5028 - mse: 0.0396 - val_loss: 29.5666 - val_mse: 0.0498\n",
      "Epoch 9/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 20.4498 - mse: 0.0394 - val_loss: 28.1527 - val_mse: 0.0496\n",
      "Epoch 10/25\n",
      "30/30 [==============================] - 51s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 20.1039 - mse: 0.0390 - val_loss: 27.0900 - val_mse: 0.0493\n",
      "Epoch 11/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 20.1216 - mse: 0.0391 - val_loss: 26.5092 - val_mse: 0.0488\n",
      "Epoch 12/25\n",
      "30/30 [==============================] - 51s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.4705 - mse: 0.0383 - val_loss: 25.3498 - val_mse: 0.0483\n",
      "Epoch 13/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.7580 - mse: 0.0390 - val_loss: 24.3999 - val_mse: 0.0475\n",
      "Epoch 14/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.5381 - mse: 0.0384 - val_loss: 22.5245 - val_mse: 0.0448\n",
      "Epoch 15/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.6235 - mse: 0.0386 - val_loss: 22.1132 - val_mse: 0.0447\n",
      "Epoch 16/25\n",
      "30/30 [==============================] - 51s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.8955 - mse: 0.0388 - val_loss: 21.3983 - val_mse: 0.0437\n",
      "Epoch 17/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.5323 - mse: 0.0385 - val_loss: 20.2624 - val_mse: 0.0412\n",
      "Epoch 18/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.1562 - mse: 0.0382 - val_loss: 19.5032 - val_mse: 0.0406\n",
      "Epoch 19/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.2595 - mse: 0.0382 - val_loss: 19.6061 - val_mse: 0.0406\n",
      "Epoch 20/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 18.9752 - mse: 0.0377 - val_loss: 19.2325 - val_mse: 0.0395\n",
      "Epoch 21/25\n",
      "30/30 [==============================] - 50s 2s/step - batch: 14.5000 - size: 125.2667 - loss: 19.0967 - mse: 0.0379 - val_loss: 18.8857 - val_mse: 0.0378\n",
      "Epoch 22/25\n",
      "21/30 [====================>.........] - ETA: 9s - batch: 10.0000 - size: 124.0952 - loss: 18.6628 - mse: 0.0374"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    x=train_generator,\n",
    "    epochs=25,\n",
    "    shuffle=True,\n",
    "    validation_data = validation_generator\n",
    ")\n",
    "model.save(\"bryan_ae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_func(y_true, y_predict, encoder_mu, encoder_log_variance):\n",
    "    '''    \n",
    "    Loss function: Kulback-Leibler Divergence + Reconstruction loss\n",
    "    Reconstruction loss is mean squared error\n",
    "    '''\n",
    "    reconstruction_loss_factor = 400\n",
    "    reconstruction_loss = K.mean(K.square(y_true - y_predict), axis=[1, 2, 3])\n",
    "    reconstruction_loss = reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=-1)\n",
    "\n",
    "    return reconstruction_loss + kl_loss\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (encoder_mu, encoder_log_variance) to sample encoder, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_mu, encoder_log_variance = inputs\n",
    "        batch = tf.shape(encoder_mu)[0]\n",
    "        dim = tf.shape(encoder_mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return encoder_mu + tf.exp(0.5 * encoder_log_variance) * epsilon\n",
    "\n",
    "\n",
    "\n",
    "latent_space_dim=256\n",
    "input_shape2=(256,256,3)\n",
    "\n",
    "'''encoder'''\n",
    "encoder_input2 = tf.keras.layers.Input(shape=input_shape2)\n",
    "net = tf.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1)(encoder_input2)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=1)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=4)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", strides=1)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "shape_before_flatten2 = K.int_shape(net)[1:]\n",
    "net = tf.keras.layers.Flatten()(net)\n",
    "encoder_mu2 = tf.keras.layers.Dense(units=latent_space_dim)(net)\n",
    "encoder_log_variance2 = tf.keras.layers.Dense(units=latent_space_dim)(net)\n",
    "\n",
    "# custom layer - will not run on DPU\n",
    "encoder_z2 = Sampling()([encoder_mu2, encoder_log_variance2])\n",
    "\n",
    "# encoder_mu,encoder_log_variance outputs go to loss function\n",
    "# encoder_z is encoded latent space\n",
    "encoder_uch=Model(inputs=encoder_input2, outputs=[encoder_mu2,encoder_log_variance2,encoder_z2])\n",
    "\n",
    "\n",
    "''' decoder '''\n",
    "decoder_input2 = tf.keras.layers.Input(shape=latent_space_dim)\n",
    "net = tf.keras.layers.Dense(units=np.prod(shape_before_flatten2))(decoder_input2)\n",
    "net = tf.keras.layers.Reshape(target_shape=shape_before_flatten2)(net)\n",
    "net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=4)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2)(net)\n",
    "net = tf.keras.layers.BatchNormalization()(net)\n",
    "net = tf.keras.layers.LeakyReLU()(net)\n",
    "decoder_output2 = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), padding=\"same\",activation='sigmoid', strides=1)(net)\n",
    "\n",
    "# standard sigmoid\n",
    "#decoder_output = Activation('sigmoid')(net)\n",
    "\n",
    "decoder_uch = Model(inputs=decoder_input2, outputs=decoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 256, 256, 1)  28          ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 256, 256, 1)  4          ['conv2d_10[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 256, 256, 1)  0           ['batch_normalization_13[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 256, 256, 32  320         ['leaky_re_lu_13[1][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 256, 256, 32  128        ['conv2d_11[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 256, 256, 32  0           ['batch_normalization_14[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 64  18496       ['leaky_re_lu_14[1][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 128, 64  256        ['conv2d_12[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 128, 128, 64  0           ['batch_normalization_15[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 64)   36928       ['leaky_re_lu_15[1][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 32, 32, 64)  256         ['conv2d_13[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 32, 32, 64)   0           ['batch_normalization_16[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 16)   9232        ['leaky_re_lu_16[1][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 32, 16)  64          ['conv2d_14[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 32, 32, 16)   0           ['batch_normalization_17[1][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 16384)        0           ['leaky_re_lu_17[1][0]']         \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256)          4194560     ['flatten_2[1][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 256)          4194560     ['flatten_2[1][0]']              \n",
      "                                                                                                  \n",
      " sampling_2 (Sampling)          (None, 256)          0           ['dense_6[1][0]',                \n",
      "                                                                  'dense_7[1][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16384)        4210688     ['sampling_2[1][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 32, 32, 16)   0           ['dense_8[1][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 64)  9280        ['reshape_1[1][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 64)  256         ['conv2d_transpose_4[1][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 32, 32, 64)   0           ['batch_normalization_18[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 128, 128, 64  36928      ['leaky_re_lu_18[1][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 128, 128, 64  256        ['conv2d_transpose_5[1][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 128, 128, 64  0           ['batch_normalization_19[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 256, 256, 64  36928      ['leaky_re_lu_19[1][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 256, 256, 64  256        ['conv2d_transpose_6[1][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 256, 256, 64  0           ['batch_normalization_20[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 3)  1731       ['leaky_re_lu_20[1][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,751,155\n",
      "Trainable params: 12,750,417\n",
      "Non-trainable params: 738\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_dim = 256\n",
    "image_chan = 3\n",
    "input_layer = tf.keras.layers.Input(shape=(image_dim,image_dim,image_chan))\n",
    "encoder_mu, encoder_log_variance, encoder_z = encoder_uch.call(input_layer)\n",
    "\n",
    "dec_out = decoder_uch.call(encoder_z)\n",
    "model_uch = Model(inputs=input_layer, outputs=dec_out)\n",
    "model_uch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uch.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=lambda y_true,y_predict: loss_func(y_true,y_predict,encoder_mu,encoder_log_variance),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 17:23:27.652596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 17:23:29.631008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38236 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-11-17 17:23:29.633032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38236 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2022-11-17 17:23:29.634861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38236 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2022-11-17 17:23:29.636551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38236 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "2022-11-17 17:23:29.698764: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 17:23:34.403425: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-11-17 17:23:35.506471: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - ETA: 0s - batch: 5.5000 - size: 121.5833 - loss: 243.3703 - mse: 0.0701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/fpga_packet/mambaforge/envs/5g/lib/python3.9/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 55s 4s/step - batch: 5.5000 - size: 121.5833 - loss: 243.3158 - mse: 0.0701 - val_loss: 49.3842 - val_mse: 0.1179\n",
      "Epoch 2/25\n",
      "12/12 [==============================] - 12s 1s/step - batch: 5.5000 - size: 121.5833 - loss: 60.9071 - mse: 0.0374 - val_loss: 48.3358 - val_mse: 0.1114\n",
      "Epoch 3/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 32.4072 - mse: 0.0348 - val_loss: 46.0251 - val_mse: 0.1073\n",
      "Epoch 4/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 23.1267 - mse: 0.0332 - val_loss: 43.7086 - val_mse: 0.1026\n",
      "Epoch 5/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 19.1333 - mse: 0.0316 - val_loss: 41.4256 - val_mse: 0.0992\n",
      "Epoch 6/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 17.2424 - mse: 0.0298 - val_loss: 40.1598 - val_mse: 0.0948\n",
      "Epoch 7/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 16.2011 - mse: 0.0291 - val_loss: 37.9656 - val_mse: 0.0913\n",
      "Epoch 8/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 15.8725 - mse: 0.0289 - val_loss: 36.8426 - val_mse: 0.0876\n",
      "Epoch 9/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 15.2766 - mse: 0.0283 - val_loss: 34.8012 - val_mse: 0.0816\n",
      "Epoch 10/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 15.2624 - mse: 0.0280 - val_loss: 33.2907 - val_mse: 0.0791\n",
      "Epoch 11/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 15.0445 - mse: 0.0281 - val_loss: 30.4377 - val_mse: 0.0724\n",
      "Epoch 12/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.7587 - mse: 0.0277 - val_loss: 28.9917 - val_mse: 0.0683\n",
      "Epoch 13/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.7607 - mse: 0.0272 - val_loss: 27.1222 - val_mse: 0.0629\n",
      "Epoch 14/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.5912 - mse: 0.0274 - val_loss: 25.3012 - val_mse: 0.0592\n",
      "Epoch 15/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.7913 - mse: 0.0278 - val_loss: 23.6736 - val_mse: 0.0548\n",
      "Epoch 16/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.6674 - mse: 0.0276 - val_loss: 22.6415 - val_mse: 0.0520\n",
      "Epoch 17/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 15.1777 - mse: 0.0276 - val_loss: 20.7877 - val_mse: 0.0472\n",
      "Epoch 18/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.5699 - mse: 0.0271 - val_loss: 19.5062 - val_mse: 0.0438\n",
      "Epoch 19/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.4650 - mse: 0.0274 - val_loss: 18.5158 - val_mse: 0.0419\n",
      "Epoch 20/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.6355 - mse: 0.0270 - val_loss: 17.5422 - val_mse: 0.0393\n",
      "Epoch 21/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 15.1866 - mse: 0.0278 - val_loss: 17.2003 - val_mse: 0.0379\n",
      "Epoch 22/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.9558 - mse: 0.0275 - val_loss: 16.2620 - val_mse: 0.0358\n",
      "Epoch 23/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.8784 - mse: 0.0273 - val_loss: 15.7985 - val_mse: 0.0352\n",
      "Epoch 24/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 14.8653 - mse: 0.0272 - val_loss: 16.1609 - val_mse: 0.0354\n",
      "Epoch 25/25\n",
      "12/12 [==============================] - 20s 2s/step - batch: 5.5000 - size: 121.5833 - loss: 15.1727 - mse: 0.0280 - val_loss: 15.3257 - val_mse: 0.0337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_uch.fit(\n",
    "    x=train_generator_uch,\n",
    "    epochs=25,\n",
    "    shuffle=True,\n",
    "    validation_data = validation_generator_uch\n",
    ")\n",
    "model_uch.save(\"uch_ae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/fpga_packet/mambaforge/envs/5g/lib/python3.9/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face = cv2.imread(\"/home/congds/class_proj/autoencoder/pics/uchtdorf1/uchtdorf/uchtdorf_face1860.jpg\")\n",
    "face = cv2.resize(face,(256,256))\n",
    "face = np.reshape(face, (1,256,256,3))\n",
    "face = face/255\n",
    "uch_pred = encoder_uch2.predict(face)\n",
    "output = decoder.predict(uch_pred)\n",
    "output = np.reshape(output,(256,256,3))\n",
    "output = output*255\n",
    "cv2.imwrite(\"/home/congds/class_proj/autoencoder/uch2bryan.png\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face = cv2.imread(\"/home/congds/class_proj/autoencoder/pics/uchtdorf1/uchtdorf/uchtdorf_face1860.jpg\")\n",
    "face = cv2.resize(face,(256,256))\n",
    "# face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "face = np.reshape(face, (1,256,256,3))\n",
    "face = face/255\n",
    "uch_pred = encoder.predict(face)\n",
    "output = decoder_uch.predict(uch_pred)\n",
    "output = np.reshape(output,(256,256,3))\n",
    "output = output*255\n",
    "print(output)\n",
    "cv2.imwrite(\"/home/congds/class_proj/autoencoder/bryan2uch.png\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = cv2.imread(\"/home/congds/class_proj/autoencoder/pics/uchtdorf1/uchtdorf/uchtdorf_face1860.jpg\")\n",
    "face = cv2.resize(face,(256,256))\n",
    "# face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "face = np.reshape(face, (1,256,256,3))\n",
    "face = face/255\n",
    "uch_pred = encoder_uch.predict(face)\n",
    "output = decoder_uch.predict(uch_pred)\n",
    "output = np.reshape(output,(256,256,3))\n",
    "output = output*255\n",
    "print(output)\n",
    "cv2.imwrite(\"/home/congds/class_proj/autoencoder/uch2uch.png\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5g",
   "language": "python",
   "name": "5g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "65ab5c996eb85f72da1c2debf2061f788467f169128745643bf45e311bc9c52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
