{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3102f550-6cb4-47a3-ada8-b1458910af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from loguru import logger\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef823f2-9348-4a16-b236-d0e4a47af4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0', '/replica:0/task:0/device:GPU:1', '/replica:0/task:0/device:GPU:2', '/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 17:03:29.558544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 17:03:31.551607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38236 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-11-17 17:03:31.553455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38236 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2022-11-17 17:03:31.555221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38236 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2022-11-17 17:03:31.557031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38236 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=gpus,cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f644fa5a-cd82-4d83-9536-a0007d40ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    training_dir = \"autoencoder/pics/bryan1\"\n",
    "    training_dir_uch = \"autoencoder/pics/uchtdorf1\"\n",
    "    image_size = (256, 256)\n",
    "    \n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=.2,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            # preprocessing_function=add_noise\n",
    "            )\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=.2,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            # preprocessing_function=add_noise\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625722ca-d574-4296-952b-bc3951779334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3758 images belonging to 1 classes.\n",
      "Found 939 images belonging to 1 classes.\n",
      "Found 1459 images belonging to 1 classes.\n",
      "Found 364 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    BATCH_SIZE = 64\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            training_dir,\n",
    "            target_size = image_size,\n",
    "            subset=\"training\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            color_mode=\"rgb\",\n",
    "            seed=42,shuffle=True)\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "            training_dir,\n",
    "            target_size=image_size,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            color_mode=\"rgb\",\n",
    "            subset=\"validation\",\n",
    "            seed=42)\n",
    "\n",
    "\n",
    "\n",
    "    train_generator_uch = train_datagen.flow_from_directory(\n",
    "            training_dir_uch,\n",
    "            target_size = image_size,\n",
    "            subset=\"training\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            color_mode=\"rgb\",\n",
    "            seed=42,shuffle=True)\n",
    "    validation_generator_uch = validation_datagen.flow_from_directory(\n",
    "            training_dir_uch,\n",
    "            target_size=image_size,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            color_mode=\"rgb\",\n",
    "            subset=\"validation\",\n",
    "            seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5fcfa7-8261-41f1-871e-b30b13672673",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = next(iter(validation_generator))\n",
    "sample_uch = next(iter(validation_generator_uch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8df2706b-9dbf-45de-8910-805fe2ae4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    latent_space_dim = 256\n",
    "    input_shape=(256,256,3)\n",
    "    class Sampling(tf.keras.layers.Layer):\n",
    "        \"\"\"Uses (encoder_mu, encoder_log_variance) to sample encoder, the vector encoding a digit.\"\"\"\n",
    "\n",
    "        def call(self, inputs):\n",
    "            encoder_mu, encoder_log_variance = inputs\n",
    "            batch = tf.shape(encoder_mu)[0]\n",
    "            dim = tf.shape(encoder_mu)[1]\n",
    "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "            return encoder_mu + tf.exp(0.5 * encoder_log_variance) * epsilon\n",
    "    '''encoder'''\n",
    "    encoder_input = tf.keras.layers.Input(shape=input_shape)\n",
    "    net = tf.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1)(encoder_input)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    net = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=1)(net)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    net = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2)(net)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    net = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=4)(net)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    net = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", strides=1)(net)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    shape_before_flatten = K.int_shape(net)[1:]\n",
    "    net = tf.keras.layers.Flatten()(net)\n",
    "\n",
    "    # custom layer - will not run on DPU\n",
    "    encoder_z = tf.keras.layers.Dense(latent_space_dim)(net)\n",
    "\n",
    "    # encoder_mu,encoder_log_variance outputs go to loss function\n",
    "    # encoder_z is encoded latent space\n",
    "    encoder=Model(inputs=encoder_input, outputs=[encoder_z])\n",
    "\n",
    "\n",
    "    ''' decoder '''\n",
    "    decoder_input = tf.keras.layers.Input(shape=latent_space_dim)\n",
    "    net = tf.keras.layers.Dense(units=np.prod(shape_before_flatten))(decoder_input)\n",
    "    net = tf.keras.layers.Reshape(target_shape=shape_before_flatten)(net)\n",
    "    net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1)(net)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=4)(net)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    net = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2)(net)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.LeakyReLU()(net)\n",
    "    decoder_output = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), padding=\"same\", activation=\"sigmoid\",strides=1)(net)\n",
    "\n",
    "\n",
    "    # standard sigmoid\n",
    "    #decoder_output = Activation('sigmoid')(net)\n",
    "\n",
    "    decoder = Model(inputs=decoder_input, outputs=decoder_output)\n",
    "    image_dim = 256\n",
    "    image_chan = 3\n",
    "    input_layer = tf.keras.layers.Input(shape=(image_dim,image_dim,image_chan))\n",
    "    encoder_z = encoder.call(input_layer)\n",
    "\n",
    "    dec_out = decoder.call(encoder_z)\n",
    "    G = Model(inputs=input_layer, outputs=dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d5396-b0af-4587-ac18-66ac2a568430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067bff63-2c50-464b-ad71-deae19e82688",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    def discriminator():\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[256, 256, 3]))\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "        model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(1))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949686c5-1b71-4df4-8d24-9485c0ba4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    D = discriminator()\n",
    "    G = G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6914f4e5-64d2-4aae-a6ee-824ae2ea9dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 256, 1)       28        \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 256, 256, 1)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 256, 256, 1)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 256, 256, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 256, 256, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 128, 128, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 16)        9232      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 32, 32, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               4194560   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16384)             4210688   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 32, 32, 64)       9280      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 128, 128, 64)     36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 128, 128, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 256, 256, 64)     36928     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 256, 256, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2D  (None, 256, 256, 3)      1731      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,556,595\n",
      "Trainable params: 8,555,857\n",
      "Non-trainable params: 738\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59a0ba65-ccfc-44a1-b094-81e603524316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 128, 128, 64)      4864      \n",
      "                                                                 \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 64, 64, 128)       204928    \n",
      "                                                                 \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 32, 32, 128)       409728    \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 131073    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750,593\n",
      "Trainable params: 750,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7aa66-7688-4e30-9429-ee84fd88c461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b09c7a-b2e6-424c-b795-dbe12dc1b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True,reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "    def generator_loss(fake_output):\n",
    "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3acef527-fbf8-43a2-8b51-a626eaf16ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    checkpoint_dir = 'autoencoder/checkpoints/train/'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                     discriminator_optimizer=discriminator_optimizer,\n",
    "                                     G=G,\n",
    "                                     D=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c0f33-88e3-4271-b305-d09b165ecdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    EPOCHS = 50\n",
    "    num_examples_to_generate = 1\n",
    "\n",
    "    # You will reuse this seed overtime (so it's easier)\n",
    "    # to visualize progress in the animated GIF)\n",
    "    seed = tf.random.normal([num_examples_to_generate,256,256,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f375d05-42ec-4c6b-bd9f-ec2ad4d2a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    @tf.function\n",
    "    def train_step(images):\n",
    "        noise = tf.random.normal([BATCH_SIZE, 256,256,3])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = G(noise, training=True)\n",
    "\n",
    "            real_output = D(images, training=True)\n",
    "            fake_output = D(generated_images, training=True)\n",
    "\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, D.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, G.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, D.trainable_variables))\n",
    "    @tf.function\n",
    "    def generate_and_save_images(model, epoch, test_input):\n",
    "      # Notice `training` is set to False.\n",
    "      # This is so all layers run in inference mode (batchnorm).\n",
    "        predictions = model(test_input, training=False)\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            # plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    @tf.function\n",
    "    def train(dataset, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            print(\"starting epoch\", epoch)\n",
    "            start = time.time()\n",
    "\n",
    "            for image_batch in dataset:\n",
    "                train_step(image_batch)\n",
    "\n",
    "            # Produce images for the GIF as you go\n",
    "            # display.clear_output(wait=True)\n",
    "            generate_and_save_images(G,\n",
    "                                     epoch + 1,\n",
    "                                     seed)\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "            if (epoch + 1) % 15 == 0:\n",
    "                checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "            print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "          # Generate after the final epoch\n",
    "    # display.clear_output(wait=True)\n",
    "        generate_and_save_images(G,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a86c3ae-5e60-4a5c-bcdd-de128e121e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 256, 1)       28        \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 256, 256, 1)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 256, 256, 1)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 256, 256, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 256, 256, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 128, 128, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 16)        9232      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 32, 32, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               4194560   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,260,272\n",
      "Trainable params: 4,259,918\n",
      "Non-trainable params: 354\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759790b-685c-4f61-bcb8-f7969d9e3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_generator, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4ea1e-3c83-42b8-9be6-a511c686abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.save(\"generator.h5\")\n",
    "D.save(\"discriminator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adbf27c-e3b5-49cb-b6d3-fe4ae1195f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5g",
   "language": "python",
   "name": "5g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
