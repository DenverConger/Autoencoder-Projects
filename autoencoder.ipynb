{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 19:39:41.942399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from loguru import logger\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4697 files belonging to 1 classes.\n",
      "Found 1823 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 19:39:42.888199: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-10 19:39:42.888744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-10 19:39:42.924695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:42.924924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.56GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 245.91GiB/s\n",
      "2022-11-10 19:39:42.924939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-10 19:39:42.926314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-10 19:39:42.926369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-10 19:39:42.927533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-10 19:39:42.927730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-10 19:39:42.928762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-10 19:39:42.929333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-10 19:39:42.931500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-10 19:39:42.931595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:42.931887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:42.932070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-10 19:39:42.932734: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-10 19:39:42.933141: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-10 19:39:42.933295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:42.933546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.56GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 245.91GiB/s\n",
      "2022-11-10 19:39:42.933567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-10 19:39:42.933593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-10 19:39:42.933602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-10 19:39:42.933610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-10 19:39:42.933617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-10 19:39:42.933626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-10 19:39:42.933635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-10 19:39:42.933643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-10 19:39:42.933690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:42.933898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:42.934078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-10 19:39:42.934097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-10 19:39:43.348587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-10 19:39:43.348607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-11-10 19:39:43.348611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-11-10 19:39:43.348768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:43.348949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:43.349055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:39:43.349144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5358 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "train_den = \"/home/denmann99/autoencoder/pics/bryan1\"\n",
    "train_uch = \"/home/denmann99/autoencoder/pics/uchtdorf1\"\n",
    "denver=tf.keras.preprocessing.image_dataset_from_directory(train_den,shuffle=True,\n",
    "                                                     batch_size=64,image_size=(256, 256),seed=123)\n",
    "uch=tf.keras.preprocessing.image_dataset_from_directory(train_uch,shuffle=True,\n",
    "                                                     batch_size=64,image_size=(256, 256),seed=123)\n",
    "def normalizer(generator):\n",
    "  normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "  def change_inputs(images, labels):\n",
    "    x = tf.image.resize(normalization_layer(images),[256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return x, x\n",
    "\n",
    "  return generator.map(change_inputs)\n",
    "normalized_denver = normalizer(denver)\n",
    "normalized_uchtdorf = normalizer(uch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 64, 64, 128)       295040    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 256, 256, 32)      18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 256, 3)       867       \n",
      "=================================================================\n",
      "Total params: 1,366,659\n",
      "Trainable params: 1,366,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoder_input = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "# Encoder\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\")(encoder_input)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "encoder_output = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "encoder= keras.Model(inputs=[encoder_input], outputs=[encoder_output])\n",
    "\n",
    "\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tf.keras.layers.Input(shape=(16,16,256))\n",
    "x = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=2, padding=\"same\")(decoder_input)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "decoder_output = tf.keras.layers.Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder= keras.Model(inputs=[decoder_input], outputs=[decoder_output])\n",
    "\n",
    "\n",
    "# Autoencoder\n",
    "input_layer = tf.keras.layers.Input(shape=(256,256,3))\n",
    "encoder_out = encoder.call(input_layer)\n",
    "decoder_out = decoder.call([encoder_out])\n",
    "ae_model = keras.Model(inputs=[input_layer], outputs=[decoder_out])\n",
    "ae_model.compile(optimizer=keras.optimizers.Adam(learning_rate=.001), loss='mse')\n",
    "print(ae_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 19:42:04.459188: W tensorflow/core/common_runtime/bfc_allocator.cc:433] Allocator (GPU_0_bfc) ran out of memory trying to allocate 512.00MiB (rounded to 536870912)requested by op gradient_tape/model_2/conv2d_4/Conv2D/Conv2DBackpropInput\n",
      "Current allocation summary follows.\n",
      "2022-11-10 19:42:04.459271: I tensorflow/core/common_runtime/bfc_allocator.cc:972] BFCAllocator dump for GPU_0_bfc\n",
      "2022-11-10 19:42:04.459303: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (256): \tTotal Chunks: 53, Chunks in use: 53. 13.2KiB allocated for chunks. 13.2KiB in use in bin. 2.5KiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459323: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459341: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 7.0KiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459361: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (2048): \tTotal Chunks: 6, Chunks in use: 6. 21.0KiB allocated for chunks. 21.0KiB in use in bin. 20.2KiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459378: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 5.2KiB allocated for chunks. 5.2KiB in use in bin. 3.4KiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459394: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459410: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459424: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459444: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (65536): \tTotal Chunks: 5, Chunks in use: 5. 360.0KiB allocated for chunks. 360.0KiB in use in bin. 360.0KiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459469: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 133.2KiB allocated for chunks. 133.2KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459499: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (262144): \tTotal Chunks: 6, Chunks in use: 6. 2.03MiB allocated for chunks. 2.03MiB in use in bin. 1.69MiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459529: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459558: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (1048576): \tTotal Chunks: 6, Chunks in use: 6. 6.75MiB allocated for chunks. 6.75MiB in use in bin. 6.75MiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459587: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 3. 6.75MiB allocated for chunks. 6.75MiB in use in bin. 6.75MiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459616: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459642: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459679: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 16.00MiB allocated for chunks. 16.00MiB in use in bin. 16.00MiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459717: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (33554432): \tTotal Chunks: 3, Chunks in use: 2. 144.00MiB allocated for chunks. 96.00MiB in use in bin. 80.00MiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459753: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (67108864): \tTotal Chunks: 6, Chunks in use: 6. 390.31MiB allocated for chunks. 390.31MiB in use in bin. 368.00MiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459800: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (134217728): \tTotal Chunks: 7, Chunks in use: 5. 944.49MiB allocated for chunks. 640.00MiB in use in bin. 640.00MiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459835: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (268435456): \tTotal Chunks: 10, Chunks in use: 9. 3.76GiB allocated for chunks. 3.50GiB in use in bin. 3.50GiB client-requested in use in bin.\n",
      "2022-11-10 19:42:04.459867: I tensorflow/core/common_runtime/bfc_allocator.cc:995] Bin for 512.00MiB was 256.00MiB, Chunk State: \n",
      "2022-11-10 19:42:04.459930: I tensorflow/core/common_runtime/bfc_allocator.cc:1001]   Size: 260.02MiB | Requested Size: 128.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 256.00MiB | Requested Size: 256.00MiB | in_use: 1 | bin_num: -1, next:   Size: 256.00MiB | Requested Size: 256.00MiB | in_use: 1 | bin_num: -1\n",
      "2022-11-10 19:42:04.459957: I tensorflow/core/common_runtime/bfc_allocator.cc:1008] Next region of size 5619194112\n",
      "2022-11-10 19:42:04.459987: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000000 of size 256 next 1\n",
      "2022-11-10 19:42:04.460009: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000100 of size 256 next 2\n",
      "2022-11-10 19:42:04.460030: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000200 of size 1280 next 3\n",
      "2022-11-10 19:42:04.460051: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000700 of size 256 next 4\n",
      "2022-11-10 19:42:04.460071: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000800 of size 256 next 5\n",
      "2022-11-10 19:42:04.460090: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000900 of size 256 next 6\n",
      "2022-11-10 19:42:04.460110: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000a00 of size 256 next 7\n",
      "2022-11-10 19:42:04.460130: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000b00 of size 256 next 11\n",
      "2022-11-10 19:42:04.460148: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000c00 of size 256 next 14\n",
      "2022-11-10 19:42:04.460166: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000d00 of size 256 next 16\n",
      "2022-11-10 19:42:04.460185: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000e00 of size 256 next 17\n",
      "2022-11-10 19:42:04.460201: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78000f00 of size 256 next 15\n",
      "2022-11-10 19:42:04.460212: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001000 of size 256 next 21\n",
      "2022-11-10 19:42:04.460222: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001100 of size 256 next 22\n",
      "2022-11-10 19:42:04.460235: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001200 of size 512 next 20\n",
      "2022-11-10 19:42:04.460246: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001400 of size 256 next 26\n",
      "2022-11-10 19:42:04.460256: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001500 of size 256 next 27\n",
      "2022-11-10 19:42:04.460266: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001600 of size 256 next 30\n",
      "2022-11-10 19:42:04.460276: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001700 of size 256 next 31\n",
      "2022-11-10 19:42:04.460287: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001800 of size 256 next 8\n",
      "2022-11-10 19:42:04.460297: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001900 of size 256 next 9\n",
      "2022-11-10 19:42:04.460308: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001a00 of size 256 next 10\n",
      "2022-11-10 19:42:04.460319: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001b00 of size 1024 next 25\n",
      "2022-11-10 19:42:04.460333: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78001f00 of size 1024 next 34\n",
      "2022-11-10 19:42:04.460346: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78002300 of size 512 next 35\n",
      "2022-11-10 19:42:04.460357: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78002500 of size 256 next 37\n",
      "2022-11-10 19:42:04.460368: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78002600 of size 256 next 40\n",
      "2022-11-10 19:42:04.460379: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78002700 of size 256 next 43\n",
      "2022-11-10 19:42:04.460389: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78002800 of size 256 next 44\n",
      "2022-11-10 19:42:04.460405: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78002900 of size 256 next 12\n",
      "2022-11-10 19:42:04.460416: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78002a00 of size 3584 next 13\n",
      "2022-11-10 19:42:04.460427: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003800 of size 256 next 45\n",
      "2022-11-10 19:42:04.460438: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003900 of size 256 next 46\n",
      "2022-11-10 19:42:04.460449: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003a00 of size 256 next 47\n",
      "2022-11-10 19:42:04.460460: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003b00 of size 256 next 48\n",
      "2022-11-10 19:42:04.460471: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003c00 of size 256 next 49\n",
      "2022-11-10 19:42:04.460482: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003d00 of size 256 next 50\n",
      "2022-11-10 19:42:04.460492: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003e00 of size 256 next 51\n",
      "2022-11-10 19:42:04.460504: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78003f00 of size 5376 next 42\n",
      "2022-11-10 19:42:04.460515: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78005400 of size 3584 next 41\n",
      "2022-11-10 19:42:04.460526: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78006200 of size 256 next 52\n",
      "2022-11-10 19:42:04.460538: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78006300 of size 136448 next 19\n",
      "2022-11-10 19:42:04.460552: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78027800 of size 73728 next 18\n",
      "2022-11-10 19:42:04.460564: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78039800 of size 73728 next 39\n",
      "2022-11-10 19:42:04.460575: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7804b800 of size 256 next 53\n",
      "2022-11-10 19:42:04.460586: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7804b900 of size 515840 next 24\n",
      "2022-11-10 19:42:04.460598: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d780c9800 of size 294912 next 23\n",
      "2022-11-10 19:42:04.460609: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78111800 of size 1179648 next 55\n",
      "2022-11-10 19:42:04.460620: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78231800 of size 1179648 next 29\n",
      "2022-11-10 19:42:04.460631: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78351800 of size 1179648 next 28\n",
      "2022-11-10 19:42:04.460642: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78471800 of size 1179648 next 36\n",
      "2022-11-10 19:42:04.460653: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78591800 of size 294912 next 38\n",
      "2022-11-10 19:42:04.460665: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d785d9800 of size 512 next 54\n",
      "2022-11-10 19:42:04.460676: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d785d9a00 of size 1024 next 56\n",
      "2022-11-10 19:42:04.460686: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d785d9e00 of size 1024 next 58\n",
      "2022-11-10 19:42:04.460698: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d785da200 of size 512 next 59\n",
      "2022-11-10 19:42:04.460709: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d785da400 of size 294912 next 60\n",
      "2022-11-10 19:42:04.460720: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78622400 of size 256 next 61\n",
      "2022-11-10 19:42:04.460731: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78622500 of size 73728 next 62\n",
      "2022-11-10 19:42:04.460742: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78634500 of size 256 next 63\n",
      "2022-11-10 19:42:04.460753: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78634600 of size 3584 next 64\n",
      "2022-11-10 19:42:04.460764: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78635400 of size 256 next 65\n",
      "2022-11-10 19:42:04.460775: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78635500 of size 3584 next 66\n",
      "2022-11-10 19:42:04.460786: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78636300 of size 256 next 67\n",
      "2022-11-10 19:42:04.460799: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78636400 of size 73728 next 68\n",
      "2022-11-10 19:42:04.460810: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78648400 of size 256 next 69\n",
      "2022-11-10 19:42:04.460823: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78648500 of size 430848 next 32\n",
      "2022-11-10 19:42:04.460834: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d786b1800 of size 2359296 next 33\n",
      "2022-11-10 19:42:04.460845: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d788f1800 of size 2359296 next 57\n",
      "2022-11-10 19:42:04.460856: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78b31800 of size 512 next 70\n",
      "2022-11-10 19:42:04.460868: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78b31a00 of size 1179648 next 71\n",
      "2022-11-10 19:42:04.460879: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78c51a00 of size 1024 next 72\n",
      "2022-11-10 19:42:04.460890: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78c51e00 of size 2359296 next 73\n",
      "2022-11-10 19:42:04.460901: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78e91e00 of size 1024 next 74\n",
      "2022-11-10 19:42:04.460913: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78e92200 of size 1179648 next 75\n",
      "2022-11-10 19:42:04.460924: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78fb2200 of size 512 next 76\n",
      "2022-11-10 19:42:04.460934: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78fb2400 of size 294912 next 77\n",
      "2022-11-10 19:42:04.460945: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78ffa400 of size 256 next 78\n",
      "2022-11-10 19:42:04.460956: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d78ffa500 of size 73728 next 79\n",
      "2022-11-10 19:42:04.460968: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900c500 of size 256 next 80\n",
      "2022-11-10 19:42:04.460979: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900c600 of size 3584 next 81\n",
      "2022-11-10 19:42:04.460990: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900d400 of size 256 next 82\n",
      "2022-11-10 19:42:04.461000: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900d500 of size 256 next 83\n",
      "2022-11-10 19:42:04.461012: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900d600 of size 256 next 84\n",
      "2022-11-10 19:42:04.461022: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900d700 of size 256 next 85\n",
      "2022-11-10 19:42:04.461033: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900d800 of size 256 next 86\n",
      "2022-11-10 19:42:04.461045: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900d900 of size 256 next 87\n",
      "2022-11-10 19:42:04.461056: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900da00 of size 256 next 88\n",
      "2022-11-10 19:42:04.461067: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900db00 of size 256 next 95\n",
      "2022-11-10 19:42:04.461078: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900dc00 of size 256 next 106\n",
      "2022-11-10 19:42:04.461088: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900dd00 of size 256 next 126\n",
      "2022-11-10 19:42:04.461100: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900de00 of size 256 next 120\n",
      "2022-11-10 19:42:04.461111: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7900df00 of size 3584 next 110\n",
      "2022-11-10 19:42:04.461122: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f0d7900ed00 of size 50327808 next 93\n",
      "2022-11-10 19:42:04.461133: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7c00de00 of size 50331648 next 127\n",
      "2022-11-10 19:42:04.461146: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7f00de00 of size 256 next 91\n",
      "2022-11-10 19:42:04.461158: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d7f00df00 of size 50331648 next 89\n",
      "2022-11-10 19:42:04.461169: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0d8200df00 of size 536870912 next 102\n",
      "2022-11-10 19:42:04.461180: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0da200df00 of size 536870912 next 103\n",
      "2022-11-10 19:42:04.461192: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0dc200df00 of size 134217728 next 114\n",
      "2022-11-10 19:42:04.461203: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0dca00df00 of size 268435456 next 117\n",
      "2022-11-10 19:42:04.461214: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0dda00df00 of size 268435456 next 111\n",
      "2022-11-10 19:42:04.461227: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0dea00df00 of size 67108864 next 119\n",
      "2022-11-10 19:42:04.461238: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0dee00df00 of size 134217728 next 115\n",
      "2022-11-10 19:42:04.461249: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0df600df00 of size 134217728 next 107\n",
      "2022-11-10 19:42:04.461261: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0dfe00df00 of size 67108864 next 112\n",
      "2022-11-10 19:42:04.461273: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e0200df00 of size 67108864 next 109\n",
      "2022-11-10 19:42:04.461284: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e0600df00 of size 16777216 next 92\n",
      "2022-11-10 19:42:04.461296: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e0700df00 of size 67108864 next 104\n",
      "2022-11-10 19:42:04.461308: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e0b00df00 of size 73728000 next 105\n",
      "2022-11-10 19:42:04.461319: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e0f65df00 of size 67108864 next 101\n",
      "2022-11-10 19:42:04.461331: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e1365df00 of size 134217728 next 94\n",
      "2022-11-10 19:42:04.461342: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f0e1b65df00 of size 138444800 next 97\n",
      "2022-11-10 19:42:04.461353: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e23a65f00 of size 134217728 next 98\n",
      "2022-11-10 19:42:04.461364: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e2ba65f00 of size 268435456 next 118\n",
      "2022-11-10 19:42:04.461376: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f0e3ba65f00 of size 272646144 next 96\n",
      "2022-11-10 19:42:04.461387: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e4be69f00 of size 268435456 next 99\n",
      "2022-11-10 19:42:04.461399: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e5be69f00 of size 536870912 next 100\n",
      "2022-11-10 19:42:04.461411: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e7be69f00 of size 541073408 next 90\n",
      "2022-11-10 19:42:04.461424: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f0e9c26bf00 of size 536870912 next 108\n",
      "2022-11-10 19:42:04.461436: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f0ebc26bf00 of size 180836864 next 18446744073709551615\n",
      "2022-11-10 19:42:04.461447: I tensorflow/core/common_runtime/bfc_allocator.cc:1033]      Summary of in-use Chunks by size: \n",
      "2022-11-10 19:42:04.461467: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 53 Chunks of size 256 totalling 13.2KiB\n",
      "2022-11-10 19:42:04.461483: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 6 Chunks of size 512 totalling 3.0KiB\n",
      "2022-11-10 19:42:04.461500: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 6 Chunks of size 1024 totalling 6.0KiB\n",
      "2022-11-10 19:42:04.461513: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-11-10 19:42:04.461527: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 6 Chunks of size 3584 totalling 21.0KiB\n",
      "2022-11-10 19:42:04.461540: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 5376 totalling 5.2KiB\n",
      "2022-11-10 19:42:04.461555: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 5 Chunks of size 73728 totalling 360.0KiB\n",
      "2022-11-10 19:42:04.461569: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 136448 totalling 133.2KiB\n",
      "2022-11-10 19:42:04.461584: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 4 Chunks of size 294912 totalling 1.12MiB\n",
      "2022-11-10 19:42:04.461599: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 430848 totalling 420.8KiB\n",
      "2022-11-10 19:42:04.461613: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 515840 totalling 503.8KiB\n",
      "2022-11-10 19:42:04.461626: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 6 Chunks of size 1179648 totalling 6.75MiB\n",
      "2022-11-10 19:42:04.461639: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 3 Chunks of size 2359296 totalling 6.75MiB\n",
      "2022-11-10 19:42:04.461654: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 16777216 totalling 16.00MiB\n",
      "2022-11-10 19:42:04.461669: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 2 Chunks of size 50331648 totalling 96.00MiB\n",
      "2022-11-10 19:42:04.461684: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 5 Chunks of size 67108864 totalling 320.00MiB\n",
      "2022-11-10 19:42:04.461697: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 73728000 totalling 70.31MiB\n",
      "2022-11-10 19:42:04.461712: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 5 Chunks of size 134217728 totalling 640.00MiB\n",
      "2022-11-10 19:42:04.461725: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 4 Chunks of size 268435456 totalling 1.00GiB\n",
      "2022-11-10 19:42:04.461738: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 4 Chunks of size 536870912 totalling 2.00GiB\n",
      "2022-11-10 19:42:04.461752: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 541073408 totalling 516.01MiB\n",
      "2022-11-10 19:42:04.461767: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Sum Total of in-use chunks: 4.63GiB\n",
      "2022-11-10 19:42:04.461780: I tensorflow/core/common_runtime/bfc_allocator.cc:1042] total_region_allocated_bytes_: 5619194112 memory_limit_: 5619194272 available bytes: 160 curr_region_allocation_bytes_: 11238388736\n",
      "2022-11-10 19:42:04.461801: I tensorflow/core/common_runtime/bfc_allocator.cc:1048] Stats: \n",
      "Limit:                      5619194272\n",
      "InUse:                      4976938496\n",
      "MaxInUse:                   5113036800\n",
      "NumAllocs:                         495\n",
      "MaxAllocSize:               2182610944\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-11-10 19:42:04.461839: W tensorflow/core/common_runtime/bfc_allocator.cc:441] *************************************************__********____**********************************___\n",
      "2022-11-10 19:42:04.461895: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_grad_input_ops.cc:1112 : Resource exhausted: OOM when allocating tensor with shape[64,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_2/conv2d_4/Conv2D/Conv2DBackpropInput (defined at tmp/ipykernel_38606/887432999.py:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_1524]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/denmann99/autoencoder/autoencoder.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/denmann99/autoencoder/autoencoder.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ae_model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/denmann99/autoencoder/autoencoder.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x\u001b[39m=\u001b[39;49mnormalized_denver,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/denmann99/autoencoder/autoencoder.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/denmann99/autoencoder/autoencoder.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/denmann99/autoencoder/autoencoder.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/denmann99/autoencoder/autoencoder.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/denmann99/autoencoder/autoencoder.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ae_model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mbryans_ae.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoencoder-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/autoencoder-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/autoencoder-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/autoencoder-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoencoder-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/autoencoder-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoencoder-env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,32,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_2/conv2d_4/Conv2D/Conv2DBackpropInput (defined at tmp/ipykernel_38606/887432999.py:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_1524]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "ae_model.fit(\n",
    "    x=normalized_denver,\n",
    "    epochs=10,\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")\n",
    "ae_model.save(\"bryans_ae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face = cv2.imread(\"/home/denmann99/autoencoder/pics/uchtdorf1/uchtdorf/uchtdorf_face2.jpg\")\n",
    "# face = cv2.resize(face,(256,256))\n",
    "# face = np.reshape(face, (1,256,256,3))\n",
    "# face = face/255\n",
    "# pred = ae_model.predict(face)\n",
    "# pred = np.reshape(pred,(256,256,3))\n",
    "# pred = pred*255\n",
    "# cv2.imwrite(\"/home/denmann99/autoencoder/Capturing.png\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_25 (Conv2DT (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_26 (Conv2DT (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_27 (Conv2DT (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_28 (Conv2DT (None, 256, 256, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 256, 256, 3)       867       \n",
      "=================================================================\n",
      "Total params: 66,499\n",
      "Trainable params: 66,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoder_input_uch = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "# Encoder\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\")(encoder_input_uch)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "encoder_output_uch = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "encoder_uch= keras.Model(inputs=[encoder_input_uch], outputs=[encoder_output_uch])\n",
    "\n",
    "\n",
    "\n",
    "# Decoder\n",
    "decoder_input_uch = tf.keras.layers.Input(shape=(16,16,256))\n",
    "x = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=2, padding=\"same\")(decoder_input_uch)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha = 0.1)(x)\n",
    "decoder_output_uch = tf.keras.layers.Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder_uch= keras.Model(inputs=[decoder_input_uch], outputs=[decoder_output_uch])\n",
    "\n",
    "\n",
    "# Autoencoder\n",
    "input_layer_uch = tf.keras.layers.Input(shape=(256,256,3))\n",
    "encoder_out_uch = encoder.call(input_layer_uch)\n",
    "decoder_out_uch = decoder.call([encoder_out_uch])\n",
    "ae_model_uch = keras.Model(inputs=[input_layer_uch], outputs=[decoder_out_uch])\n",
    "ae_model_uch.compile(optimizer=keras.optimizers.Adam(learning_rate=.001), loss='mse')\n",
    "print(ae_model_uch.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 15s 470ms/step - loss: 0.0087\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 14s 462ms/step - loss: 0.0036\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 14s 459ms/step - loss: 0.0029\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 14s 462ms/step - loss: 0.0027\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 15s 476ms/step - loss: 0.0026\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 14s 466ms/step - loss: 0.0025\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 14s 460ms/step - loss: 0.0025\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 15s 486ms/step - loss: 0.0024\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 16s 518ms/step - loss: 0.0023\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 15s 483ms/step - loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "ae_model_uch.fit(\n",
    "    x=normalized_uchtdorf,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "ae_model_uch.save(\"uchtdorf_ae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff66c388a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 19:32:00.628022: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff66c388700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 19:32:01.251407: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face = cv2.imread(\"/home/denmann99/autoencoder/pics/uchtdorf1/uchtdorf/uchtdorf_face2.jpg\")\n",
    "face = cv2.resize(face,(256,256))\n",
    "face = np.reshape(face, (1,256,256,3))\n",
    "face = face/255\n",
    "uch_pred = encoder_uch.predict(face)\n",
    "output = decoder.predict(uch_pred)\n",
    "output = np.reshape(output,(256,256,3))\n",
    "output = output*255\n",
    "cv2.imwrite(\"/home/denmann99/autoencoder/uch2bryan.png\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('autoencoder-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65ab5c996eb85f72da1c2debf2061f788467f169128745643bf45e311bc9c52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
